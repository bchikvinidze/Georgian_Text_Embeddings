1) მონაცემების შეგროვებიs იდეებში წერია შემდეგი:
სტატიის სათაური - სტატიის მთავარი ნაწილი
ვიკიპედიის სექცია - შესაბამისი პარაგრაფი 
კითხვა - პასუხი
რაიმე ტექსტი - მისი შემოკლებული/შეჯამებული ვერსია
უკვე არსებული ინგლისურენოვანი pair dataset-ების გადათარგმნა

მერე პირობაში წერია:
კონსტრასტული სწავლების დროს მოდელს ვაჩვენებთ დადებით (კითხვა - სწორი პასუხი) და უარყოფით (კითხვა - არასწორი პასუხი) ტექსტის წყვილებს

ჰოდა ანუ არ გამოდის რომ ზემოთ ჩამოთვლილთაგან მხოლოდ კითხვა-პასუხის ვარიანტები გვაწყობს query და passage ნაწილში? იმიტომ რომ ტექსტი/შემაჯამებელი ვერსია < ამით რა უნდა ისწავლოს მოდელმა?

2) როგორ უნდა შევაფასოთ რომელი ლოს ფუნქცია გვირჩევნია? 
3) მონაცემების მოგროვება ყველაზე მარტივია მგონი თარგმნით - არსებული მზა დატასეტ რომ ავიღოთ. მარტო ეს მიდგომა რომ გვქონდეს გამოყენებული ამის ნაკლი რა არის? მაგ. gpt-4o რომგ
გამოვიყენო თარგმანშ რომელიც  გუგლ თრანსლეითზე უკეთესია.
4) როგორ გავტესტოთ თარგმანის ხარისხი?
5) რამდენად ბევრი დატას შეგროვება მოგვიწევს დაახლოებით? მაგ. 1000 წყვილი ძალიან ცოტაა? 100 წყვილი? 10 წყვილი?
